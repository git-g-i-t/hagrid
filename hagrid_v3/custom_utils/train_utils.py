import os
from typing import List, Tuple

import torch
from omegaconf import DictConfig
from torch.utils.data import DataLoader, Dataset
from torch.utils.tensorboard import SummaryWriter

from custom_utils.utils import Logger, build_model, get_transform
from models import HaGRIDModel

# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å®žéªŒå¯å¤çŽ°
from .utils import set_random_seed

set_random_seed()


def get_available_device():
    """
    èŽ·å–å¯ç”¨è®¾å¤‡ï¼Œä¼˜å…ˆä½¿ç”¨ GPUï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨ CPU
    """
    if torch.cuda.is_available():
        return "cuda:0"  # ä½¿ç”¨ç¬¬ä¸€ä¸ª GPU
    else:
        return "cpu"


def collate_fn(batch: List) -> Tuple:
    """
    DataLoader çš„æ•´ç†å‡½æ•°
    é»˜è®¤çš„ collate_fn å°è¯•å°†æ‰€æœ‰æ•°æ®å †å (stack)æˆ Tensorï¼Œä½†è¿™å¯¹äºŽç›®æ ‡æ£€æµ‹ä¸é€‚ç”¨ï¼Œ
    å› ä¸ºæ¯å¼ å›¾çš„ BBox æ•°é‡ä¸åŒã€‚è¿™é‡Œåªæ˜¯ç®€å•åœ°å°† batch æ‰“åŒ…æˆå…ƒç»„åˆ—è¡¨ã€‚

    Parameters
    ----------
    batch : List
        [ (img1, target1), (img2, target2), ... ]
    """
    return list(zip(*batch))


def get_dataloader(dataset: Dataset, **kwargs) -> DataLoader:
    """
    æž„å»º PyTorch DataLoader çš„å·¥åŽ‚å‡½æ•°

    Parameters
    ----------
    dataset : Dataset
        æ•°æ®é›†å®žä¾‹
    **kwargs
        åŒ…å« batch_size, num_workers ç­‰å‚æ•°
    """
    return DataLoader(
        dataset,
        collate_fn=collate_fn,
        shuffle=kwargs["shuffle"],
        batch_size=kwargs["batch_size"],
        num_workers=kwargs["num_workers"],
        prefetch_factor=kwargs["prefetch_factor"],
    )


def load_train_objects(config: DictConfig, command: str, n_gpu: int):
    """
    æ ¸å¿ƒå·¥åŽ‚å‡½æ•°ï¼šåŠ è½½è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰å¯¹è±¡ (æ•°æ®ã€æ¨¡åž‹)
    æ ¹æ®é…ç½®æ–‡ä»¶è‡ªåŠ¨åˆ¤æ–­æ˜¯åŠ è½½æ£€æµ‹ä»»åŠ¡è¿˜æ˜¯åˆ†ç±»ä»»åŠ¡çš„ Datasetã€‚

    Parameters
    ----------
    config : DictConfig
        å…¨å±€é…ç½®
    command : str [train, test]
        å½“å‰æ¨¡å¼
    n_gpu : int
        GPU æ•°é‡ï¼ˆä¿ç•™å‚æ•°ï¼Œä½†å®žé™…åªæ”¯æŒå•è®¾å¤‡ï¼‰

    Returns
    -------
    Tuple
        (train_loader, val_loader, test_loader, model)
    """
    # 1. æž„å»ºæ¨¡åž‹ç»“æž„
    model = build_model(config)

    # 2. æ ¹æ®æ¨¡åž‹ç±»åž‹é€‰æ‹©å¯¹åº”çš„æ•°æ®é›†ç±»
    if model.type == "detector":
        from dataset import DetectionDataset as GestureDataset
    elif model.type == "classifier":
        from dataset import ClassificationDataset as GestureDataset
    else:
        raise Exception(f"Model type {model.type} does not exist")

    # 3. åˆå§‹åŒ–æµ‹è¯•é›† (æ— è®ºè®­ç»ƒè¿˜æ˜¯æµ‹è¯•æ¨¡å¼éƒ½éœ€è¦)
    test_dataset = GestureDataset(config, "test", get_transform(config.test_transforms, model.type))

    # 4. å¦‚æžœæ˜¯è®­ç»ƒæ¨¡å¼ï¼Œåˆå§‹åŒ–è®­ç»ƒé›†å’ŒéªŒè¯é›†
    if command == "train":
        train_dataset = GestureDataset(config, "train", get_transform(config.train_transforms, model.type))
        if config.dataset.dataset_val and config.dataset.annotations_val:
            val_dataset = GestureDataset(config, "val", get_transform(config.val_transforms, model.type))
        else:
            raise Exception("Cannot train without validation data")
    else:
        train_dataset = None
        val_dataset = None

    # 5. æž„å»º DataLoaders
    test_dataloader = get_dataloader(test_dataset, **config.test_params)
    if command == "train":
        train_dataloader = get_dataloader(train_dataset, **config.train_params)
        if val_dataset:
            val_dataloader = get_dataloader(val_dataset, **config.val_params)
        else:
            val_dataloader = None
    else:
        # æµ‹è¯•æ¨¡å¼ä¸éœ€è¦è®­ç»ƒ/éªŒè¯åŠ è½½å™¨
        train_dataloader = None
        val_dataloader = None

    return train_dataloader, val_dataloader, test_dataloader, model


def load_train_optimizer(model: HaGRIDModel, config: DictConfig):
    """
    åŠ è½½ä¼˜åŒ–å™¨ (Optimizer) å’Œ å­¦ä¹ çŽ‡è°ƒåº¦å™¨ (Scheduler)
    """
    # è¿‡æ»¤æŽ‰ä¸éœ€è¦æ¢¯åº¦çš„å‚æ•° (ä¾‹å¦‚å†»ç»“çš„ä¸»å¹²ç½‘ç»œ)
    parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]
    
    # åŠ¨æ€èŽ·å–ä¼˜åŒ–å™¨ç±» (å¦‚ torch.optim.SGD) å¹¶åˆå§‹åŒ–
    optimizer = getattr(torch.optim, config.optimizer.name)(parameters, **config.optimizer.params)
    
    # åŠ¨æ€èŽ·å–è°ƒåº¦å™¨ç±» (å¦‚ torch.optim.lr_scheduler.StepLR) å¹¶åˆå§‹åŒ–
    if hasattr(config, 'scheduler') and hasattr(config.scheduler, 'name') and config.scheduler.name:
        try:
            scheduler = getattr(torch.optim.lr_scheduler, config.scheduler.name)(optimizer, **config.scheduler.params)
        except AttributeError:
            print(f"âš ï¸  è°ƒåº¦å™¨ {config.scheduler.name} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ StepLR")
            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
    else:
        scheduler = None
    return optimizer, scheduler


class Trainer:
    """
    è®­ç»ƒæ€»ç®¡ï¼šç®¡ç†è®­ç»ƒå¾ªçŽ¯ã€éªŒè¯ã€ä¿å­˜æ¨¡åž‹ç­‰æ‰€æœ‰é€»è¾‘
    """
    def __init__(
        self,
        model: HaGRIDModel,
        config: DictConfig,
        test_data: torch.utils.data.DataLoader,
        train_data: torch.utils.data.DataLoader = None,
        val_data: torch.utils.data.DataLoader = None,
        metric_calculator=None,
        n_gpu: int = 1,
        optimizer: torch.optim.Optimizer = None,
        scheduler: torch.optim.lr_scheduler.LRScheduler = None,
        log_subdir: str = None,  # æ–°å¢žå‚æ•°ï¼šæ—¥å¿—å­ç›®å½•
    ) -> None:
        self.train_data = train_data
        self.test_data = test_data
        self.val_data = val_data
        
        # è®¾å¤‡è®¾ç½®
        self.device = get_available_device()
        print(f"ðŸŽ¯ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        self.model = model
        self.model.to(self.device)

        # ç¡®å®šè¯„ä»·æŒ‡æ ‡åç§°
        if self.model.type == "classifier":
            self.metric_name = "F1Score"
        else:
            self.metric_name = "map" # Mean Average Precision
            
        self.config = config
        self.optimizer = optimizer
        self.scheduler = scheduler

        # åˆå§‹åŒ–çŠ¶æ€è®°å½•
        self.current_state = {
            "loss": 0,
            "metric": {self.metric_name: 0},
            "epoch": 0,
        }
        self.best_state = {
            "loss": 0,
            "metric": {self.metric_name: 0},
            "epoch": 0,
        }

        self.stop = False
        self.max_epoch = self.config.epochs
        self.epochs_run = 0
        self.n_gpu = n_gpu
        
        # ç§»åŠ¨è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨åˆ°è®¾å¤‡
        try:
            self.metric_calculator = metric_calculator.to(self.device)
        except Exception as e:
            print(f"âš ï¸  è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨ç§»åŠ¨è®¾å¤‡å¤±è´¥: {e}")
            print("âš ï¸  è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨å°†ä¿æŒåœ¨åŽŸè®¾å¤‡")
            self.metric_calculator = metric_calculator

        # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨å’Œæ–‡ä»¶å¤¹
        if not os.path.exists(self.config.work_dir):
            os.mkdir(self.config.work_dir)
        
        # åˆå§‹åŒ– TensorBoard Writer (è‡ªåŠ¨åˆ†æµé€»è¾‘)
        log_path = f"{self.config.work_dir}/{self.config.experiment_name}/logs"
        if log_subdir:
            log_path = os.path.join(log_path, log_subdir)
            
        self.summary_writer = SummaryWriter(log_dir=log_path)
        self.summary_writer.add_text("model/name", self.config.model.name)

        # å¦‚æžœæœ‰ Checkpointï¼ŒåŠ è½½æ–­ç‚¹
        if self.config.model.checkpoint is not None:
            self._load_snapshot(self.config.model.checkpoint)

    def _save_snapshot(self):
        """
        ä¿å­˜æ¨¡åž‹æƒé‡å’Œè®­ç»ƒçŠ¶æ€
        """
        metric_score = self.best_state["metric"][self.metric_name]
        
        # èŽ·å–æ¨¡åž‹çŠ¶æ€
        state = self.model.state_dict()
            
        snapshot = {
            "MODEL_STATE": state,
            "OPTIMIZER_STATE": self.optimizer.state_dict(),
            "SCHEDULER_STATE": self.scheduler.state_dict() if self.scheduler else None,
            "EPOCHS_RUN": self.best_state["epoch"],
            "Loss": self.best_state["loss"],
            "Metric": self.best_state["metric"],
        }
        save_path = os.path.join(self.config.work_dir, self.config.experiment_name)
        # æ–‡ä»¶ååŒ…å« epoch, metric åˆ†æ•°å’Œ lossï¼Œæ–¹ä¾¿æŸ¥çœ‹    1.0è¿™é‡Œæ”¹äº†ä¸€ä¸‹ï¼Œwindowsä¸èƒ½ä½¿ç”¨ï¼šï¼Œæ¢æˆäº†_
        save_name = f"{self.config.model.name}_epoch-{self.best_state['epoch']}_{self.metric_name}-{metric_score:.2}_loss-{self.best_state['loss']:.2}.pth"
        if not os.path.exists(save_path):
            os.mkdir(save_path)
        torch.save(snapshot, os.path.join(save_path, save_name))
        print(f"Save model {self.config.model.name} || {self.metric_name}:{metric_score:.2}")

    def _load_snapshot(self, snapshot_path):
        """
        åŠ è½½æ–­ç‚¹ç»§ç»­è®­ç»ƒ
        """
        snapshot = torch.load(snapshot_path, map_location=self.device)
        self.model.load_state_dict(snapshot["MODEL_STATE"])
        self.optimizer.load_state_dict(snapshot["OPTIMIZER_STATE"])
        if self.scheduler and "SCHEDULER_STATE" in snapshot and snapshot["SCHEDULER_STATE"]:
            self.scheduler.load_state_dict(snapshot["SCHEDULER_STATE"])
        self.epochs_run = snapshot["EPOCHS_RUN"]
        # æ¢å¤æœ€ä½³çŠ¶æ€è®°å½•ï¼Œé˜²æ­¢åˆšå¼€å§‹è®­ç»ƒå°±è¦†ç›–äº†ä¹‹å‰çš„æœ€ä½³æ¨¡åž‹
        self.best_state["epoch"] = snapshot["EPOCHS_RUN"]
        self.best_state["loss"] = snapshot["Loss"]
        self.best_state["metric"] = snapshot["Metric"]
        print(f"Loaded model from {snapshot_path}")

    def test(self):
        """
        åœ¨æµ‹è¯•é›†ä¸Šè¿è¡ŒæŽ¨ç†
        """
        self.model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
        if self.test_data is None:
            raise Exception("Cannot test without test data")

        # Logger æ˜¯è‡ªå®šä¹‰çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºŽæ‰“å°æ¼‚äº®çš„è¿›åº¦æ¡
        with Logger("Test", self.max_epoch, len(self.test_data), self.config.log_every, self.device) as logger:
            for iteration, (images, targets) in enumerate(self.test_data):
                # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
                images = [image.to(self.device) for image in images]
                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]

                with torch.no_grad(): # ç¦ç”¨æ¢¯åº¦è®¡ç®—
                    output = self.model(images)

                # è®¡ç®—æŒ‡æ ‡
                metric = self.metric_calculator(output, targets)

                logger.log_iteration(iteration + 1, self.current_state["epoch"], metrics=metric)

            # è®°å½•åˆ° TensorBoard
            for key, value in metric.items():
                self.summary_writer.add_scalar(f"{key}/Test", value, self.current_state["epoch"])

    def val(self):
        """
        åœ¨éªŒè¯é›†ä¸Šè¿è¡ŒæŽ¨ç†å¹¶ä¿å­˜æœ€ä½³æ¨¡åž‹
        """
        self.model.eval()
        if self.val_data is None:
            raise Exception("Cannot validate without validation data")
        with Logger("Eval", self.max_epoch, len(self.val_data), self.config.log_every, self.device) as logger:
            for iteration, (images, targets) in enumerate(self.val_data):
                images = [image.to(self.device) for image in images]
                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]

                with torch.no_grad():
                    output = self.model(images)

                metric = self.metric_calculator(output, targets)
                logger.log_iteration(iteration + 1, self.current_state["epoch"], metrics=metric)

            # ç»Ÿè®¡å’Œä¿å­˜æ¨¡åž‹
            self.current_state["metric"] = logger.metric_averager.value

            for key, value in self.current_state["metric"].items():
                self.summary_writer.add_scalar(f"{key}/Eval", value, self.current_state["epoch"])

            # --- æ ¸å¿ƒé€»è¾‘ï¼šä¿å­˜æœ€ä½³æ¨¡åž‹ ---
            # å¦‚æžœå½“å‰æŒ‡æ ‡æ¯”åŽ†å²æœ€ä½³è¿˜è¦å¥½ (è¶…è¿‡äº†é˜ˆå€¼)ï¼Œåˆ™æ›´æ–°æœ€ä½³çŠ¶æ€å¹¶ä¿å­˜
            if (
                self.current_state["metric"][self.metric_name] - self.best_state["metric"][self.metric_name]
            ) > self.config.early_stopping.metric:
                self.best_state["metric"] = self.current_state["metric"]
                self.best_state["loss"] = self.current_state["loss"]
                self.best_state["epoch"] = self.current_state["epoch"]

                self._save_snapshot()

    def early_stop(self):
        """
        æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ—©åœæ¡ä»¶ (è€å¿ƒå€¼è€—å°½ä¸”æŒ‡æ ‡æœªæå‡)
        """
        if (
            self.current_state["epoch"] - self.best_state["epoch"] >= self.config.early_stopping.epochs
            and self.current_state["metric"][self.metric_name] - self.best_state["metric"][self.metric_name]
            <= self.config.early_stopping.metric
        ):
            return True
        else:
            return False

    def train(self):
        """
        ä¸»è®­ç»ƒå¾ªçŽ¯
        """
        if self.train_data is None:
            raise Exception("Cannot train without training data")
        
        # å¾ªçŽ¯ Epoch
        for epoch in range(self.epochs_run, self.max_epoch):
            # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ—©åœ
            if self.early_stop():
                self.stop = True
                
            if self.stop:
                break

            # 2. è®¾ç½®è®­ç»ƒæ¨¡å¼
            self.model.train()
            self.current_state["epoch"] = epoch
                
            with Logger("Train", self.max_epoch, len(self.train_data), self.config.log_every, self.device) as logger:
                # å¾ªçŽ¯ Batch
                for iteration, (images, targets) in enumerate(self.train_data):
                    self.optimizer.zero_grad() # æ¸…ç©ºæ¢¯åº¦

                    # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                    images = [image.to(self.device) for image in images]
                    targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]

                    # å‰å‘ä¼ æ’­è®¡ç®— Loss
                    loss = self.model(images, targets)

                    # åå‘ä¼ æ’­
                    loss.backward()
                    self.optimizer.step()

                    logger.log_iteration(iteration + 1, self.current_state["epoch"], loss.item())

                # æ›´æ–°å­¦ä¹ çŽ‡
                if self.scheduler is not None:
                    if hasattr(self.config.scheduler, 'name') and self.config.scheduler.name == "ReduceLROnPlateau":
                        self.scheduler.step(self.current_state["loss"])
                    else:
                        self.scheduler.step()

                # è®°å½• Loss åˆ° TensorBoard
                self.current_state["loss"] = logger.loss_averager.value
                self.summary_writer.add_scalar(
                    "loss/Train", self.current_state["loss"], self.current_state["epoch"]
                )

            # å®šæœŸéªŒè¯
            if self.config.eval_every > 0 and self.current_state["epoch"] % self.config.eval_every == 0:
                self.val()

            # å®šæœŸæµ‹è¯•
            if self.config.test_every > 0 and self.current_state["epoch"] % self.config.test_every == 0:
                self.test()