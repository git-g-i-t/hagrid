import os
import sys
import argparse
import cv2
import numpy as np
import torch
from PIL import Image
from torchvision import transforms
from omegaconf import OmegaConf
import matplotlib.pyplot as plt

# è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
# é¡¹ç›®æ ¹ç›®å½• (hagrid)
project_root = os.path.abspath(os.path.join(current_dir, ".."))
# hagrid_v2 ç›®å½•
hagrid_v2_path = os.path.join(project_root, "hagrid_v2")

# å°†è¿™ä¸¤ä¸ªè·¯å¾„éƒ½æ·»åŠ åˆ° sys.path
sys.path.append(project_root)
sys.path.append(hagrid_v2_path)
# å°è¯•å¯¼å…¥ grad-cam åº“
try:
    from pytorch_grad_cam import GradCAM
    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
    from pytorch_grad_cam.utils.image import show_cam_on_image
except ImportError:
    print("âŒ é”™è¯¯: æœªæ‰¾åˆ° 'grad-cam' åº“ã€‚")
    print("è¯·è¿è¡Œ: pip install grad-cam")
    exit(1)

# å¯¼å…¥ä½ çš„æ¨¡å‹æ„å»ºå‡½æ•°
from hagrid_v2.custom_utils.utils import build_model

def get_args():
    # ========================================================
    # âœ¨ åœ¨è¿™é‡Œä¿®æ”¹ä½ çš„é»˜è®¤è·¯å¾„å’Œå‚æ•° âœ¨
    # ========================================================
    DEFAULT_CONFIG = "hagrid_v2\\configs\\cbam_resnet18.yaml"      # é…ç½®æ–‡ä»¶è·¯å¾„
    DEFAULT_CHECKPOINT = "hagrid_v2\\work_dir\\CBAM_ResNet18_Attention\\CBAM_ResNet18_epoch-29_F1Score-0.78_loss-0.44.pth"              # æƒé‡æ–‡ä»¶è·¯å¾„
    DEFAULT_IMAGE_DIR = "hagrid_v2/dataset_mini/test"          # æµ‹è¯•å›¾ç‰‡æ–‡ä»¶å¤¹
    DEFAULT_OUTPUT_DIR = "results/gradcam/cbam_resnet18"                    # ç»“æœä¿å­˜è·¯å¾„
    DEFAULT_TARGET_LAYER = "layer4"                           # ç›®æ ‡å·ç§¯å±‚
    DEFAULT_NUM_IMAGES = 5                                    # é»˜è®¤å¤„ç†å›¾ç‰‡å¼ æ•°
    # ========================================================

    parser = argparse.ArgumentParser(description="Generate Grad-CAM visualizations")
    
    parser.add_argument("--config", type=str, default=DEFAULT_CONFIG, 
                        help=f"Path to config file (default: {DEFAULT_CONFIG})")
    
    parser.add_argument("--checkpoint", type=str, default=DEFAULT_CHECKPOINT, 
                        help=f"Path to model checkpoint (default: {DEFAULT_CHECKPOINT})")
    
    parser.add_argument("--image_dir", type=str, default=DEFAULT_IMAGE_DIR, 
                        help=f"Directory with test images (default: {DEFAULT_IMAGE_DIR})")
    
    parser.add_argument("--output_dir", type=str, default=DEFAULT_OUTPUT_DIR, 
                        help=f"Directory to save results (default: {DEFAULT_OUTPUT_DIR})")
    
    parser.add_argument("--target_layer", type=str, default=DEFAULT_TARGET_LAYER, 
                        help=f"Target layer for Grad-CAM (default: {DEFAULT_TARGET_LAYER})")
    
    parser.add_argument("--num_images", type=int, default=DEFAULT_NUM_IMAGES, 
                        help=f"Number of images to visualize (default: {DEFAULT_NUM_IMAGES})")
    
    return parser.parse_args()

def preprocess_image(img_path, img_size=224):
    """
    è¯»å–å¹¶é¢„å¤„ç†å›¾ç‰‡
    """
    # è¯»å–åŸå§‹å›¾ç‰‡ç”¨äºæ˜¾ç¤º
    raw_bgr = cv2.imread(img_path)
    if raw_bgr is None:
        raise FileNotFoundError(f"æ— æ³•è¯»å–å›¾ç‰‡: {img_path}")
        
    rgb_img = raw_bgr[:, :, ::-1] # BGR -> RGB
    rgb_img = cv2.resize(rgb_img, (img_size, img_size))
    rgb_img_float = np.float32(rgb_img) / 255.0 # å½’ä¸€åŒ–åˆ° [0, 1] ç”¨äº grad-cam

    # é¢„å¤„ç†ç”¨äºæ¨¡å‹è¾“å…¥
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.54, 0.499, 0.474], std=[0.234, 0.235, 0.231])
    ])
    
    input_tensor = transform(rgb_img).unsqueeze(0) # (1, C, H, W)
    return rgb_img_float, input_tensor

def main():
    args = get_args()
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.checkpoint):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ '{args.checkpoint}'ï¼Œè¯·æ£€æŸ¥ DEFAULT_CHECKPOINT è®¾ç½®ã€‚")
        return

    # 1. å‡†å¤‡ç¯å¢ƒ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    os.makedirs(args.output_dir, exist_ok=True)
    
    # 2. åŠ è½½é…ç½®å’Œæ¨¡å‹
    print(f"ğŸš€ Loading config from {args.config}...")
    conf = OmegaConf.load(args.config)
    
    print(f"ğŸ“¦ Building model {conf.model.name}...")
    conf.model.pretrained = False 
    model = build_model(conf)
    
    # åŠ è½½æƒé‡
    print(f"ğŸ’¾ Loading checkpoint from {args.checkpoint}...")
    checkpoint = torch.load(args.checkpoint, map_location=device)
    
    state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint
    new_state_dict = {}
    for k, v in state_dict.items():
        name = k.replace("module.", "") if k.startswith("module.") else k
        name = name.replace("hagrid_model.", "") if name.startswith("hagrid_model.") else name
        new_state_dict[name] = v
        
    try:
        model.hagrid_model.load_state_dict(new_state_dict, strict=False)
    except RuntimeError as e:
        print(f"âš ï¸ æƒé‡åŠ è½½éƒ¨åˆ†ä¸åŒ¹é…: {e}")

    model.to(device)
    model.eval()

    # 3. è®¾ç½® Grad-CAM ç›®æ ‡å±‚
    try:
        target_layers = [getattr(model.hagrid_model, args.target_layer)[-1]]
        cam = GradCAM(model=model.hagrid_model, target_layers=target_layers)
    except Exception as e:
        print(f"âŒ ç›®æ ‡å±‚è®¾ç½®é”™è¯¯: {e}. è¯·æ£€æŸ¥ --target_layer æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚ 'layer4'ï¼‰ã€‚")
        return

    # 4. éå†å›¾ç‰‡å¹¶ç”Ÿæˆçƒ­åŠ›å›¾
    image_paths = []
    for root, dirs, files in os.walk(args.image_dir):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_paths.append(os.path.join(root, file))
                if len(image_paths) >= args.num_images:
                    break
        if len(image_paths) >= args.num_images:
            break
            
    if not image_paths:
        print(f"âŒ åœ¨ {args.image_dir} ä¸‹æ²¡æ‰¾åˆ°å›¾ç‰‡ï¼")
        return

    print(f"ğŸ“¸ Processing {len(image_paths)} images...")

    for i, img_path in enumerate(image_paths):
        try:
            filename = os.path.basename(img_path)
            print(f"[{i+1}/{len(image_paths)}] Processing {filename}...")
            
            rgb_img, input_tensor = preprocess_image(img_path, img_size=conf.dataset.img_size)
            input_tensor = input_tensor.to(device)
            
            with torch.no_grad():
                output = model.hagrid_model(input_tensor)
                pred_idx = output.argmax(dim=1).item()
                conf_score = output.softmax(dim=1).max().item()
            
            grayscale_cam = cam(input_tensor=input_tensor, targets=None)
            grayscale_cam = grayscale_cam[0, :]
            
            visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
            
            plt.figure(figsize=(10, 5))
            plt.subplot(1, 2, 1)
            plt.imshow(rgb_img)
            plt.title(f"Original: {filename}")
            plt.axis('off')
            
            plt.subplot(1, 2, 2)
            plt.imshow(visualization)
            plt.title(f"Grad-CAM (Pred: {pred_idx}, Conf: {conf_score:.2f})")
            plt.axis('off')
            
            save_path = os.path.join(args.output_dir, f"gradcam_{filename}")
            plt.tight_layout()
            plt.savefig(save_path)
            plt.close()
            
            print(f"âœ… Saved to {save_path}")
            
        except Exception as e:
            print(f"âŒ Failed to process {img_path}: {e}")

    print(f"\nğŸ‰ All Done! Results saved in '{args.output_dir}'")

if __name__ == "__main__":
    main()