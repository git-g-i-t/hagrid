# è¿™ä¸ªæ–‡ä»¶æ˜¯é¡¹ç›®çš„é€šç”¨å·¥å…·ç®±
# åŒ…å«äº†è¯„ä»·æŒ‡æ ‡è®¡ç®—ã€æ—¥å¿—è®°å½•ã€å›¾åƒå¢žå¼ºæž„å»ºã€æ¨¡åž‹æž„å»ºå·¥åŽ‚ä»¥åŠéšæœºç§å­è®¾ç½®ç­‰åŸºç¡€åŠŸèƒ½ã€‚
# å®ƒæ˜¯è¿žæŽ¥é…ç½®ï¼ˆConfigï¼‰ã€æ¨¡åž‹ï¼ˆModelï¼‰å’Œè®­ç»ƒæµç¨‹ï¼ˆTrainerï¼‰çš„çº½å¸¦ã€‚
import random
from collections import defaultdict
from time import gmtime, strftime
from typing import Dict

import albumentations as A
import numpy as np
import torch
from albumentations.pytorch import ToTensorV2
from omegaconf import DictConfig
from torchmetrics import F1Score
from omegaconf import OmegaConf 
# å¯¼å…¥è‡ªå®šä¹‰çš„æ¨¡åž‹åˆ—è¡¨ï¼ˆåœ¨ models/__init__.py ä¸­å®šä¹‰ï¼‰
from models import classifiers_list, detectors_list

TORCH_VERSION = torch.__version__


def get_available_device():
    """
    èŽ·å–å¯ç”¨è®¾å¤‡ï¼Œä¼˜å…ˆä½¿ç”¨ GPUï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨ CPU
    """
    if torch.cuda.is_available():
        return "cuda:0"  # ä½¿ç”¨ç¬¬ä¸€ä¸ª GPU
    else:
        return "cpu"


class F1ScoreWithLogging:
    """
    å¯¹ torchmetrics.F1Score çš„å°è£…ç±»ã€‚
    ä¸»è¦ä½œç”¨æ˜¯é€‚é… Trainer çš„æŽ¥å£ï¼Œå¤„ç†è¾“å…¥è¾“å‡ºæ ¼å¼ï¼Œå¹¶æ”¯æŒç§»åŠ¨åˆ° GPUã€‚
    """
    def __init__(self, task, num_classes):
        """
        Parameters
        ----------
        task : str
            ä»»åŠ¡ç±»åž‹ ('binary' æˆ– 'multiclass')
        num_classes : int
            ç±»åˆ«æ•°é‡
        """
        # åˆå§‹åŒ– F1Score è®¡ç®—å™¨
        self.f1_score = F1Score(task=task, num_classes=num_classes)
        self.device = get_available_device()

    def to(self, device):
        """
        å°†æŒ‡æ ‡è®¡ç®—å™¨ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ (CPU/GPU)
        æ”¯æŒè‡ªåŠ¨é™çº§åˆ° CPU
        """
        # å¦‚æžœè¯·æ±‚çš„æ˜¯ CUDA ä½†ä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§åˆ° CPU
        if "cuda" in str(device) and not torch.cuda.is_available():
            device = "cpu"
            print(f"è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨: CUDA ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° {device}")
        
        try:
            self.f1_score = self.f1_score.to(device)
            self.device = device
        except Exception as e:
            print(f"è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨ç§»åŠ¨è®¾å¤‡å¤±è´¥: {e}")
            print("è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨å°†ä¿æŒåœ¨åŽŸè®¾å¤‡")
        
        return self

    def __call__(self, preds, targets):
        """
        è®¡ç®— F1 åˆ†æ•°
        
        Parameters
        ----------
        preds : dict
            æ¨¡åž‹è¾“å‡ºçš„é¢„æµ‹ç»“æžœï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« "labels" (logits/probs)
        targets : list
            çœŸå®žæ ‡ç­¾åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ (åŒ…å« "labels")
        """
        # å°† target åˆ—è¡¨å †å æˆ Tensor
        target = torch.stack([target["labels"] for target in targets])
        
        # èŽ·å–é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•
        pred_labels = preds["labels"].to(self.device).argmax(1)
        
        # =========== ðŸ•µï¸â€â™‚ï¸ è°ƒè¯•ä»£ç å¼€å§‹  ===========
        # æ‰“å°å‰10ä¸ªé¢„æµ‹ç»“æžœå’ŒçœŸå®žæ ‡ç­¾ï¼Œçœ‹çœ‹å®ƒåˆ°åº•åœ¨çŒœä»€ä¹ˆ
        print(f"\n[DEBUG] é¢„æµ‹: {pred_labels[:10].tolist()}")
        print(f"[DEBUG] çœŸå®ž: {target[:10].tolist()}")
        # =========== ðŸ•µï¸â€â™‚ï¸ è°ƒè¯•ä»£ç ç»“æŸ ===========================


        # preds["labels"].argmax(1): èŽ·å–æ¦‚çŽ‡æœ€å¤§çš„ç±»åˆ«ç´¢å¼•
        # è®¡ç®—é¢„æµ‹å€¼ä¸ŽçœŸå®žå€¼çš„ F1 åˆ†æ•°
        result = self.f1_score(preds["labels"].argmax(1), target)
        
        # è¿”å›žå­—å…¸æ ¼å¼ï¼Œæ–¹ä¾¿ Logger è®°å½•
        return {"F1Score": result}


class Logger:
    """
    è‡ªå®šä¹‰æ—¥å¿—è®°å½•å™¨ (Context Manager)
    åŠŸèƒ½ï¼š
    1. æ ¼å¼åŒ–æ‰“å°è®­ç»ƒè¿›åº¦ã€æ—¶é—´ã€Loss å’Œ Metricsã€‚
    2. ç»´æŠ¤ Loss å’Œ Metrics çš„æ»‘åŠ¨å¹³å‡å€¼ (Averager)ã€‚
    3. åªåœ¨ä¸»è®¾å¤‡ä¸Šæ‰“å°ï¼Œé¿å…å¤šå¡è®­ç»ƒæ—¶åˆ·å±ã€‚
    """
    def __init__(self, train_state: str, max_epochs: int, dataloader_len: int, log_every: int, device: str = "cpu"):
        """
        Parameters
        ----------
        train_state : str
            å½“å‰çŠ¶æ€: "Train", "Eval" æˆ– "Test"
        max_epochs : int
            æ€» Epoch æ•°
        dataloader_len : int
            å½“å‰ DataLoader çš„é•¿åº¦ (Batch æ€»æ•°)
        log_every : int
            æ¯éš”å¤šå°‘ä¸ª iteration æ‰“å°ä¸€æ¬¡æ—¥å¿—
        device : str
            å½“å‰ä½¿ç”¨çš„è®¾å¤‡
        """
        self.dataloader_len = dataloader_len
        self.max_epochs = max_epochs
        self.train_state = train_state
        self.log_every = log_every
        self.device = device
        # åˆå§‹åŒ–å¹³å‡å€¼è®¡ç®—å™¨
        self.loss_averager = LossAverager()
        self.metric_averager = MetricAverager()

    def log_iteration(self, iteration: int, epoch: int, loss: float = None, metrics: dict = None):
        """
        è®°å½•å½“å‰è¿­ä»£çš„ä¿¡æ¯
        """
        # åªæœ‰åœ¨æŒ‡å®šçš„é—´éš” (log_every) æˆ–æœ€åŽä¸€ä¸ª batch æ—¶æ‰æ‰“å°
        if (iteration % self.log_every == 0) or (iteration == self.dataloader_len):
            # èŽ·å–å½“å‰æ—¶é—´
            log_str = f"Time: {strftime('%Y-%m-%d %H:%M:%S', gmtime())} "
            log_str += f"{self.train_state} ---- Epoch [{epoch}/{self.max_epochs}], Iteration [{iteration}/{self.dataloader_len}]:"
            
            # å¦‚æžœæ˜¯è®­ç»ƒé˜¶æ®µï¼Œè®°å½• Loss
            if self.train_state == "Train" and loss is not None:
                self.loss_averager.update(loss)
                log_str += f" Loss: {self.loss_averager.value}"
            
            # å¦‚æžœæ˜¯éªŒè¯/æµ‹è¯•é˜¶æ®µï¼Œè®°å½• Metrics
            if self.train_state in ["Eval", "Test"] and metrics is not None:
                # æ¸…ç†æŽ‰ä¸éœ€è¦æ‰“å°çš„ key (å¦‚æžœæœ‰çš„è¯)
                try:
                    del metrics["classes"]
                except KeyError:
                    pass
                
                self.metric_averager.update(metrics)
                
                # åªæœ‰åœ¨è·‘å®Œæ•´ä¸ªéªŒè¯é›†åŽ (æœ€åŽä¸€ä¸ª iteration)ï¼Œæ‰æ‰“å°æœ€ç»ˆçš„å¹³å‡æŒ‡æ ‡
                if iteration == self.dataloader_len:
                    for metric_name, metric_value in self.metric_averager.value.items():
                        log_str += f" {metric_name}: {metric_value}"
            print(log_str)

    # ä¸Šä¸‹æ–‡ç®¡ç†å™¨åè®®ï¼šæ”¯æŒ `with Logger(...) as logger:` è¯­æ³•
    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        pass


class MetricAverager:
    """
    æŒ‡æ ‡å¹³å‡å€¼è®¡ç®—å™¨
    ç”¨äºŽåœ¨éªŒè¯è¿‡ç¨‹ä¸­ç´¯åŠ æ¯ä¸ª Batch çš„æŒ‡æ ‡ï¼Œæœ€åŽæ±‚å¹³å‡ã€‚
    """
    def __init__(self):
        self.current_total = defaultdict(float) # ä½¿ç”¨ defaultdict é˜²æ­¢ key ä¸å­˜åœ¨æŠ¥é”™
        self.iterations = 0

    def update(self, values: Dict):
        for key, value in values.items():
            self.current_total[key] += value.item()
        self.iterations += 1

    @property
    def value(self):
        if self.iterations == 0:
            return 0
        else:
            # è®¡ç®—å¹³å‡å€¼
            metrics = {key: value / self.iterations for key, value in self.current_total.items()}
            return metrics


class LossAverager:
    """
    Loss å¹³å‡å€¼è®¡ç®—å™¨
    """
    def __init__(self):
        self.iterations = 0
        self.current_total = 0

    def update(self, value):
        self.current_total += value
        self.iterations += 1

    @property
    def value(self):
        if self.iterations == 0:
            return 0
        else:
            return self.current_total / self.iterations


def get_transform(transform_config: DictConfig, model_type: str):
    """
    æž„å»ºæ•°æ®å¢žå¼º Pipeline
    ä¿®å¤äº† ListConfig ç±»åž‹å¯¼è‡´çš„ TypeError
    """
    transforms_list = []
    
    for key, params in transform_config.items():
        # OmegaConf è¯»å–çš„å‚æ•°æ˜¯ DictConfig/ListConfig ç±»åž‹
        # Albumentations ä¸è®¤è¿™äº›ç±»åž‹ï¼Œå¿…é¡»è½¬å›ž Python åŽŸç”Ÿçš„ dict/list
        real_params = OmegaConf.to_container(params, resolve=True)
        
        # å®žä¾‹åŒ–å¢žå¼ºæ–¹æ³•
        transforms_list.append(getattr(A, key)(**real_params))

    transforms_list.append(ToTensorV2())

    if model_type == "detector":
        return A.Compose(
            transforms_list,
            bbox_params=A.BboxParams(format="pascal_voc", min_area=0, min_visibility=0, label_fields=["class_labels"]),
        )
    elif model_type == "classifier":
        return A.Compose(transforms_list)


def build_model(config: DictConfig):
    """
    æ¨¡åž‹æž„å»ºå·¥åŽ‚å‡½æ•°
    æ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„ model.name å®žä¾‹åŒ–å¯¹åº”çš„æ¨¡åž‹ã€‚
    """
    model_name = config.model.name
   
    # è¿™æ ·æ— è®ºä»¥åŽæ˜¯ç”¨ 7 ç±»ã€18 ç±»è¿˜æ˜¯ 34 ç±»ï¼Œä»£ç éƒ½èƒ½è‡ªåŠ¨é€‚åº”ï¼Œä¸ç”¨å†æ”¹äº†
    model_config = {"num_classes": len(config.dataset.targets), "pretrained": config.model.pretrained}
   
    # æƒ…å†µ 1: ç›®æ ‡æ£€æµ‹æ¨¡åž‹ (å¦‚ SSDLite)
    if model_name in detectors_list:
        # æ£€æµ‹ä»»åŠ¡é€šå¸¸éœ€è¦ä¸€ä¸ªé¢å¤–çš„ "èƒŒæ™¯" ç±»ï¼Œæ‰€ä»¥ +1 (å˜æˆ 35 ç±»)
        model_config["num_classes"] += 1
        # æ›´æ–°æ£€æµ‹æ¨¡åž‹ç‰¹æœ‰çš„é…ç½® (è¾“å…¥å°ºå¯¸ã€å‡å€¼æ–¹å·®ç”¨äºŽ Backbone é¢„å¤„ç†)
        model_config.update(
            {
                "pretrained_backbone": config.model.pretrained_backbone,
                "img_size": config.dataset.img_size,
                "img_mean": config.dataset.img_mean,
                "img_std": config.dataset.img_std,
            }
        )
        # å®žä¾‹åŒ–æ£€æµ‹æ¨¡åž‹
        model = detectors_list[model_name](**model_config)
        # æ‰“ä¸Šæ ‡è®°ï¼ŒåŽç»­ load_train_objects ä¼šæ ¹æ®è¿™ä¸ªæ ‡è®°åŠ è½½ DetectionDataset
        model.type = "detector"
        
    # æƒ…å†µ 2: å›¾åƒåˆ†ç±»æ¨¡åž‹ (å¦‚ ResNet, MobileNet)
    elif model_name in classifiers_list:
        # å®žä¾‹åŒ–åˆ†ç±»æ¨¡åž‹
        model = classifiers_list[model_name](**model_config)
        # ç»‘å®šæŸå¤±å‡½æ•° (å¦‚ CrossEntropyLoss)
        model.criterion = getattr(torch.nn, config.criterion)()
        # æ‰“ä¸Šæ ‡è®°ï¼ŒåŽç»­ä¼šåŠ è½½ ClassificationDataset
        model.type = "classifier"
    else:
        raise Exception(f"Unknown model {model_name}")

    return model


def set_random_seed(seed: int = 42, deterministic: bool = False) -> int:
    """
    è®¾ç½®éšæœºç§å­ï¼Œä¿è¯å®žéªŒå¯å¤çŽ°ã€‚

    Args:
        seed (int, optional): ç§å­å€¼.
        deterministic (bool): æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ç¡®å®šæ€§ç®—æ³• (ä¼šé™ä½Žè®­ç»ƒé€Ÿåº¦ä½†ä¿è¯ç»“æžœå®Œå…¨ä¸€è‡´).
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    
    if torch.cuda.is_available():
        # ä¸ºæ‰€æœ‰ GPU è®¾ç½®ç§å­
        torch.cuda.manual_seed_all(seed)
        
    if deterministic:
        if torch.backends.cudnn.benchmark:
            print(
                "torch.backends.cudnn.benchmark is going to be set as "
                "`False` to cause cuDNN to deterministically select an "
                "algorithm"
            )
        # ç¦ç”¨ cudnn benchmark (è‡ªåŠ¨å¯»æ‰¾æœ€å¿«ç®—æ³•)ï¼Œå› ä¸ºå®ƒæœ‰éšæœºæ€§
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

        if TORCH_VERSION >= "1.10.0":
            torch.use_deterministic_algorithms(True)
    return seed